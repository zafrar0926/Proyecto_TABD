{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827fdffc",
   "metadata": {},
   "source": [
    "# PRUEBA EJECUCI√ìN EXPERIMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15c435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Procesando colecci√≥n: laps_enriched ===\n",
      "üì• Leyendo MongoDB filtrado desde 2024 ...\n",
      "üóëÔ∏è Eliminando hist√≥rico desde 2024 en topicos-bases-datos.f1_data_warehouse.laps_enriched\n",
      "‚¨ÜÔ∏è Insertando 48805 filas nuevas en topicos-bases-datos.f1_data_warehouse.laps_enriched ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserci√≥n completada: topicos-bases-datos.f1_data_warehouse.laps_enriched\n",
      "\n",
      "=== Procesando colecci√≥n: race_control ===\n",
      "üì• Leyendo MongoDB filtrado desde 2024 ...\n",
      "üóëÔ∏è Eliminando hist√≥rico desde 2024 en topicos-bases-datos.f1_data_warehouse.race_control\n",
      "‚¨ÜÔ∏è Insertando 4134 filas nuevas en topicos-bases-datos.f1_data_warehouse.race_control ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserci√≥n completada: topicos-bases-datos.f1_data_warehouse.race_control\n",
      "\n",
      "=== Procesando colecci√≥n: results ===\n",
      "üì• Leyendo MongoDB filtrado desde 2024 ...\n",
      "üóëÔ∏è Eliminando hist√≥rico desde 2024 en topicos-bases-datos.f1_data_warehouse.results\n",
      "‚¨ÜÔ∏è Insertando 998 filas nuevas en topicos-bases-datos.f1_data_warehouse.results ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserci√≥n completada: topicos-bases-datos.f1_data_warehouse.results\n",
      "\n",
      "=== Procesando colecci√≥n: weather ===\n",
      "üì• Leyendo MongoDB filtrado desde 2024 ...\n",
      "üóëÔ∏è Eliminando hist√≥rico desde 2024 en topicos-bases-datos.f1_data_warehouse.weather\n",
      "‚¨ÜÔ∏è Insertando 7147 filas nuevas en topicos-bases-datos.f1_data_warehouse.weather ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserci√≥n completada: topicos-bases-datos.f1_data_warehouse.weather\n",
      "\n",
      "=== MIGRACI√ìN INCREMENTAL COMPLETA ===\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# üöÄ PROYECTO F1 - MongoDB ‚Üí BigQuery (Carga incremental limpia)\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime\n",
    "import os\n",
    "import certifi\n",
    "\n",
    "# ===============================================================\n",
    "# üîß PAR√ÅMETROS VARIABLES (AQU√ç SOLO CAMBIAS ESTO)\n",
    "# ===============================================================\n",
    "\n",
    "LOAD_FROM_YEAR = 2024              # <-- Cambia este a√±o para traer desde Mongo (ej: 2025)\n",
    "LOAD_FROM_DATE = \"2024-01-01\"      # <-- Si la colecci√≥n usa EventDate\n",
    "DELETE_SINCE_YEAR = 2024           # <-- Lo que vas a borrar en BigQuery\n",
    "DELETE_SINCE_DATE = \"2024-01-01\"   # <-- Para tablas que usan DATE\n",
    "\n",
    "# ===============================================================\n",
    "# üîß CONFIGURACI√ìN GENERAL\n",
    "# ===============================================================\n",
    "\n",
    "MONGO_URI = \"mongodb+srv://santiago_bigq_access:26092510@cluster0.otgxigz.mongodb.net/?retryWrites=true&w=majority\"\n",
    "MONGO_DB = \"f1_data_warehouse\"\n",
    "COLLECTIONS = [\"laps_enriched\", \"race_control\", \"results\", \"weather\"]\n",
    "\n",
    "PROJECT_ID = \"topicos-bases-datos\"\n",
    "DATASET = \"f1_data_warehouse\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = (\n",
    "    r\"C:\\Users\\santi\\Downloads\\Learning\\Maestria\\Topicos Avanzados en Bases de Datos\\Proyecto Final\\Entrega\\Core\\2. From_Mongo_to_BigQuery\\topicos-bases-datos-0af108d2076b.json\"\n",
    ")\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "mongo_client = MongoClient(\n",
    "    MONGO_URI,\n",
    "    tls=True,\n",
    "    tlsCAFile=certifi.where()\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "# üß© FUNCIONES DE LIMPIEZA\n",
    "# ===============================================================\n",
    "\n",
    "def parse_time(val):\n",
    "    if pd.isna(val) or val == \"\":\n",
    "        return None\n",
    "    for fmt in (\"%H:%M:%S.%f\", \"%H:%M:%S\"):\n",
    "        try:\n",
    "            return datetime.strptime(val, fmt).time()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_timestamp(val):\n",
    "    if pd.isna(val) or val == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        return pd.to_datetime(val, errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_dataframe(df, collection_name):\n",
    "    df = df.copy()\n",
    "\n",
    "    string_time_fields = {\n",
    "        \"Sector1_Throttle_100_Time\", \"Sector1_Brake_Time\", \"Sector1_Throttle_Time\", \"Sector1_Coasting_Time\",\n",
    "        \"Sector2_Throttle_100_Time\", \"Sector2_Brake_Time\", \"Sector2_Throttle_Time\", \"Sector2_Coasting_Time\",\n",
    "        \"Sector3_Throttle_100_Time\", \"Sector3_Brake_Time\", \"Sector3_Throttle_Time\", \"Sector3_Coasting_Time\"\n",
    "    }\n",
    "\n",
    "    for col in df.columns:\n",
    "        if \"Time\" in col and col not in string_time_fields:\n",
    "            df[col] = df[col].apply(parse_time)\n",
    "        elif \"Date\" in col:\n",
    "            if col == \"LapStartDate\":\n",
    "                df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            else:\n",
    "                df[col] = pd.to_datetime(df[col], errors=\"coerce\").dt.date\n",
    "        elif \"Timestamp\" in col:\n",
    "            df[col] = df[col].apply(parse_timestamp)\n",
    "        elif df[col].dtype == object:\n",
    "            df[col] = df[col].replace({\"nan\": None, \"NaN\": None, \"\": None})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# üìò ESQUEMAS FIJOS\n",
    "# -------------------------------\n",
    "SCHEMAS = {\n",
    "    \"laps_enriched\": bigquery.SchemaField(\"Time\", \"TIME\", \"NULLABLE\"),\n",
    "    # (solo se declara el primero a modo de marcador, el esquema completo se define abajo)\n",
    "}\n",
    "\n",
    "def schema_laps_enriched():\n",
    "    # Lista recortada a campos √∫nicos por longitud (puedes ampliarla con todos si lo deseas)\n",
    "    fields = [\n",
    "        bigquery.SchemaField(\"Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Driver\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"DriverNumber\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"LapTime\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"LapNumber\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Stint\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"PitOutTime\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"PitInTime\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Sector1Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Sector2Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Sector3Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"SpeedI1\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"SpeedI2\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"SpeedFL\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"SpeedST\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"IsPersonalBest\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"Compound\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TyreLife\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"FreshTyre\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"Team\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"LapStartTime\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"LapStartDate\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"TrackStatus\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"Position\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Deleted\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"DeletedReason\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FastF1Generated\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"IsAccurate\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"EventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"SessionName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Country\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Location\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"OfficialEventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"EventDate\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"EventFormat\", \"STRING\"),\n",
    "    ]\n",
    "    return fields\n",
    "\n",
    "def schema_race_control():\n",
    "    return [\n",
    "        bigquery.SchemaField(\"Time\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"Category\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Message\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Status\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Flag\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Scope\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Sector\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"RacingNumber\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"Lap\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"EventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"SessionName\", \"STRING\"),\n",
    "    ]\n",
    "\n",
    "def schema_results():\n",
    "    return [\n",
    "        bigquery.SchemaField(\"DriverNumber\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"BroadcastName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Abbreviation\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"DriverId\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TeamName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TeamColor\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TeamId\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FirstName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"LastName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FullName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"HeadshotUrl\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"CountryCode\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Position\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"ClassifiedPosition\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"GridPosition\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Q1\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Q2\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Q3\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Status\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Points\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Laps\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"EventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"SessionName\", \"STRING\"),\n",
    "    ]\n",
    "\n",
    "def schema_weather():\n",
    "    return [\n",
    "        bigquery.SchemaField(\"Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"AirTemp\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Humidity\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Pressure\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Rainfall\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"TrackTemp\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"WindDirection\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"WindSpeed\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"EventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"SessionName\", \"STRING\"),\n",
    "    ]\n",
    "# ===============================================================\n",
    "# üöÄ MIGRACI√ìN INCREMENTAL Y LIMPIA\n",
    "# ===============================================================\n",
    "\n",
    "for collection_name in COLLECTIONS:\n",
    "    print(f\"\\n=== Procesando colecci√≥n: {collection_name} ===\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 1. Leer desde Mongo SOLO lo del a√±o seleccionado\n",
    "    # -----------------------------------------------------------\n",
    "    print(f\"üì• Leyendo MongoDB filtrado desde {LOAD_FROM_YEAR} ...\")\n",
    "\n",
    "    mongo_filter = {\"Year\": {\"$gte\": LOAD_FROM_YEAR}}\n",
    "    mongo_docs = list(mongo_client[MONGO_DB][collection_name].find(mongo_filter))\n",
    "\n",
    "    df = pd.json_normalize(mongo_docs)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è No hay datos de {collection_name} para el a√±o {LOAD_FROM_YEAR}.\")\n",
    "        continue\n",
    "\n",
    "    if \"_id\" in df.columns:\n",
    "        df = df.drop(columns=[\"_id\"])\n",
    "\n",
    "    df = clean_dataframe(df, collection_name)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 2. Borrar datos del hist√≥rico en BigQuery (por a√±o o fecha)\n",
    "    # -----------------------------------------------------------\n",
    "    final_table = f\"{PROJECT_ID}.{DATASET}.{collection_name}\"\n",
    "\n",
    "    print(f\"üóëÔ∏è Eliminando hist√≥rico desde {DELETE_SINCE_YEAR} en {final_table}\")\n",
    "\n",
    "    if collection_name == \"laps_enriched\":\n",
    "        delete_query = f\"\"\"\n",
    "        DELETE FROM `{final_table}`\n",
    "        WHERE EventDate >= DATE('{DELETE_SINCE_DATE}');\n",
    "        \"\"\"\n",
    "    else:\n",
    "        delete_query = f\"\"\"\n",
    "        DELETE FROM `{final_table}`\n",
    "        WHERE Year >= {DELETE_SINCE_YEAR};\n",
    "        \"\"\"\n",
    "\n",
    "    bq_client.query(delete_query).result()\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 3. Insertar los datos nuevos desde Mongo ‚Üí tabla oficial\n",
    "    # -----------------------------------------------------------\n",
    "    print(f\"‚¨ÜÔ∏è Insertando {len(df)} filas nuevas en {final_table} ...\")\n",
    "\n",
    "    cfg = TABLE_CONFIGS[collection_name]\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=cfg[\"schema\"],\n",
    "        write_disposition=\"WRITE_APPEND\"\n",
    "    )\n",
    "\n",
    "    bq_client.load_table_from_dataframe(df, final_table, job_config=job_config).result()\n",
    "\n",
    "    print(f\"‚úÖ Inserci√≥n completada: {final_table}\")\n",
    "\n",
    "print(\"\\n=== MIGRACI√ìN INCREMENTAL COMPLETA ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47297191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Procesando colecci√≥n: laps_enriched ===\n",
      "üì• Leyendo MongoDB SOLO para el a√±o 2024 ...\n",
      "üóëÔ∏è Eliminando en BigQuery SOLO el a√±o 2024 en topicos-bases-datos.f1_data_warehouse.laps_enriched\n",
      "‚¨ÜÔ∏è Insertando 29024 filas del a√±o 2024 en topicos-bases-datos.f1_data_warehouse.laps_enriched ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserci√≥n completada para laps_enriched (2024)\n",
      "\n",
      "=== Procesando colecci√≥n: race_control ===\n",
      "üì• Leyendo MongoDB SOLO para el a√±o 2024 ...\n",
      "üóëÔ∏è Eliminando en BigQuery SOLO el a√±o 2024 en topicos-bases-datos.f1_data_warehouse.race_control\n",
      "‚¨ÜÔ∏è Insertando 2318 filas del a√±o 2024 en topicos-bases-datos.f1_data_warehouse.race_control ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserci√≥n completada para race_control (2024)\n",
      "\n",
      "=== Procesando colecci√≥n: results ===\n",
      "üì• Leyendo MongoDB SOLO para el a√±o 2024 ...\n",
      "üóëÔ∏è Eliminando en BigQuery SOLO el a√±o 2024 en topicos-bases-datos.f1_data_warehouse.results\n",
      "‚¨ÜÔ∏è Insertando 599 filas del a√±o 2024 en topicos-bases-datos.f1_data_warehouse.results ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserci√≥n completada para results (2024)\n",
      "\n",
      "=== Procesando colecci√≥n: weather ===\n",
      "üì• Leyendo MongoDB SOLO para el a√±o 2024 ...\n",
      "üóëÔ∏è Eliminando en BigQuery SOLO el a√±o 2024 en topicos-bases-datos.f1_data_warehouse.weather\n",
      "‚¨ÜÔ∏è Insertando 4161 filas del a√±o 2024 en topicos-bases-datos.f1_data_warehouse.weather ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserci√≥n completada para weather (2024)\n",
      "\n",
      "=== üöÄ MIGRACI√ìN ANUAL COMPLETADA ===\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# üöÄ PROYECTO F1 - MongoDB ‚Üí BigQuery (Carga anual limpia)\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime\n",
    "import os\n",
    "import certifi\n",
    "\n",
    "# ===============================================================\n",
    "# üîß PAR√ÅMETRO PRINCIPAL (SOLO CAMBIAS ESTE)\n",
    "# ===============================================================\n",
    "\n",
    "LOAD_YEAR = 2024    # <-- CLAVE: pon 2024 o 2025, y SOLO cargar√° ese a√±o\n",
    "LOAD_DATE = f\"{LOAD_YEAR}-01-01\"   # por si se requiere por fecha\n",
    "\n",
    "# ===============================================================\n",
    "# üîß CONFIGURACI√ìN GENERAL\n",
    "# ===============================================================\n",
    "\n",
    "MONGO_URI = \"mongodb+srv://santiago_bigq_access:26092510@cluster0.otgxigz.mongodb.net/?retryWrites=true&w=majority\"\n",
    "MONGO_DB = \"f1_data_warehouse\"\n",
    "COLLECTIONS = [\"laps_enriched\", \"race_control\", \"results\", \"weather\"]\n",
    "\n",
    "PROJECT_ID = \"topicos-bases-datos\"\n",
    "DATASET = \"f1_data_warehouse\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = (\n",
    "    r\"C:\\Users\\santi\\Downloads\\Learning\\Maestria\\Topicos Avanzados en Bases de Datos\\Proyecto Final\\Entrega\\Core\\2. From_Mongo_to_BigQuery\\topicos-bases-datos-0af108d2076b.json\"\n",
    ")\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "mongo_client = MongoClient(\n",
    "    MONGO_URI,\n",
    "    tls=True,\n",
    "    tlsCAFile=certifi.where()\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "# üß© FUNCIONES DE LIMPIEZA\n",
    "# ===============================================================\n",
    "\n",
    "def parse_time(val):\n",
    "    if pd.isna(val) or val == \"\":\n",
    "        return None\n",
    "    for fmt in (\"%H:%M:%S.%f\", \"%H:%M:%S\"):\n",
    "        try:\n",
    "            return datetime.strptime(val, fmt).time()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_timestamp(val):\n",
    "    if pd.isna(val) or val == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        return pd.to_datetime(val, errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_dataframe(df, collection_name):\n",
    "    df = df.copy()\n",
    "\n",
    "    string_time_fields = {\n",
    "        \"Sector1_Throttle_100_Time\", \"Sector1_Brake_Time\", \"Sector1_Throttle_Time\", \"Sector1_Coasting_Time\",\n",
    "        \"Sector2_Throttle_100_Time\", \"Sector2_Brake_Time\", \"Sector2_Throttle_Time\", \"Sector2_Coasting_Time\",\n",
    "        \"Sector3_Throttle_100_Time\", \"Sector3_Brake_Time\", \"Sector3_Throttle_Time\", \"Sector3_Coasting_Time\"\n",
    "    }\n",
    "\n",
    "    for col in df.columns:\n",
    "        if \"Time\" in col and col not in string_time_fields:\n",
    "            df[col] = df[col].apply(parse_time)\n",
    "        elif \"Date\" in col:\n",
    "            if col == \"LapStartDate\":\n",
    "                df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            else:\n",
    "                df[col] = pd.to_datetime(df[col], errors=\"coerce\").dt.date\n",
    "        elif \"Timestamp\" in col:\n",
    "            df[col] = df[col].apply(parse_timestamp)\n",
    "        elif df[col].dtype == object:\n",
    "            df[col] = df[col].replace({\"nan\": None, \"NaN\": None, \"\": None})\n",
    "\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# üìò ESQUEMAS FIJOS\n",
    "# -------------------------------\n",
    "SCHEMAS = {\n",
    "    \"laps_enriched\": bigquery.SchemaField(\"Time\", \"TIME\", \"NULLABLE\"),\n",
    "    # (solo se declara el primero a modo de marcador, el esquema completo se define abajo)\n",
    "}\n",
    "\n",
    "def schema_laps_enriched():\n",
    "    # Lista recortada a campos √∫nicos por longitud (puedes ampliarla con todos si lo deseas)\n",
    "    fields = [\n",
    "        bigquery.SchemaField(\"Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Driver\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"DriverNumber\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"LapTime\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"LapNumber\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Stint\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"PitOutTime\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"PitInTime\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Sector1Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Sector2Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Sector3Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"SpeedI1\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"SpeedI2\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"SpeedFL\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"SpeedST\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"IsPersonalBest\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"Compound\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TyreLife\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"FreshTyre\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"Team\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"LapStartTime\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"LapStartDate\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"TrackStatus\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"Position\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Deleted\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"DeletedReason\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FastF1Generated\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"IsAccurate\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"EventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"SessionName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Country\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Location\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"OfficialEventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"EventDate\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"EventFormat\", \"STRING\"),\n",
    "    ]\n",
    "    return fields\n",
    "\n",
    "def schema_race_control():\n",
    "    return [\n",
    "        bigquery.SchemaField(\"Time\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"Category\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Message\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Status\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Flag\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Scope\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Sector\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"RacingNumber\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"Lap\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"EventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"SessionName\", \"STRING\"),\n",
    "    ]\n",
    "\n",
    "def schema_results():\n",
    "    return [\n",
    "        bigquery.SchemaField(\"DriverNumber\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"BroadcastName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Abbreviation\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"DriverId\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TeamName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TeamColor\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"TeamId\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FirstName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"LastName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"FullName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"HeadshotUrl\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"CountryCode\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Position\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"ClassifiedPosition\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"GridPosition\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Q1\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Q2\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Q3\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"Status\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Points\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Laps\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"EventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"SessionName\", \"STRING\"),\n",
    "    ]\n",
    "\n",
    "def schema_weather():\n",
    "    return [\n",
    "        bigquery.SchemaField(\"Time\", \"TIME\"),\n",
    "        bigquery.SchemaField(\"AirTemp\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Humidity\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Pressure\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Rainfall\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"TrackTemp\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"WindDirection\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"WindSpeed\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"EventName\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"SessionName\", \"STRING\"),\n",
    "    ]\n",
    "\n",
    "# ===============================================================\n",
    "# üöÄ MIGRACI√ìN ANUAL (SOLO EL A√ëO MARCADO)\n",
    "# ===============================================================\n",
    "\n",
    "for collection_name in COLLECTIONS:\n",
    "    print(f\"\\n=== Procesando colecci√≥n: {collection_name} ===\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 1. Leer desde Mongo solo el a√±o seleccionado\n",
    "    # -----------------------------------------------------------\n",
    "    print(f\"üì• Leyendo MongoDB SOLO para el a√±o {LOAD_YEAR} ...\")\n",
    "\n",
    "    mongo_filter = {\"Year\": LOAD_YEAR}\n",
    "    mongo_docs = list(mongo_client[MONGO_DB][collection_name].find(mongo_filter))\n",
    "\n",
    "    df = pd.json_normalize(mongo_docs)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è No hay datos de {collection_name} para el a√±o {LOAD_YEAR}.\")\n",
    "        continue\n",
    "\n",
    "    if \"_id\" in df.columns:\n",
    "        df = df.drop(columns=[\"_id\"])\n",
    "\n",
    "    df = clean_dataframe(df, collection_name)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 2. Borrar SOLO ese a√±o de la tabla oficial\n",
    "    # -----------------------------------------------------------\n",
    "    final_table = f\"{PROJECT_ID}.{DATASET}.{collection_name}\"\n",
    "\n",
    "    print(f\"üóëÔ∏è Eliminando en BigQuery SOLO el a√±o {LOAD_YEAR} en {final_table}\")\n",
    "\n",
    "    if collection_name == \"laps_enriched\":\n",
    "        delete_query = f\"\"\"\n",
    "        DELETE FROM `{final_table}`\n",
    "        WHERE EXTRACT(YEAR FROM EventDate) = {LOAD_YEAR};\n",
    "        \"\"\"\n",
    "    else:\n",
    "        delete_query = f\"\"\"\n",
    "        DELETE FROM `{final_table}`\n",
    "        WHERE Year = {LOAD_YEAR};\n",
    "        \"\"\"\n",
    "\n",
    "    bq_client.query(delete_query).result()\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 3. Insertar SOLO ese a√±o\n",
    "    # -----------------------------------------------------------\n",
    "    print(f\"‚¨ÜÔ∏è Insertando {len(df)} filas del a√±o {LOAD_YEAR} en {final_table} ...\")\n",
    "\n",
    "    cfg = TABLE_CONFIGS[collection_name]\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=cfg[\"schema\"],\n",
    "        write_disposition=\"WRITE_APPEND\"\n",
    "    )\n",
    "\n",
    "    bq_client.load_table_from_dataframe(df, final_table, job_config=job_config).result()\n",
    "\n",
    "    print(f\"‚úÖ Inserci√≥n completada para {collection_name} ({LOAD_YEAR})\")\n",
    "\n",
    "print(\"\\n=== üöÄ MIGRACI√ìN ANUAL COMPLETADA ===\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
